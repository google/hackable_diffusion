{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training MNIST using flax.linen and convert to nnx.\n",
        "\n",
        "In this colab we showcase how to train a diffusion model on MNIST dataset. This colab can run on any colab backend.\n",
        "\n",
        "We showcase that the library works with `flax.linen` and `flax.nnx`. We train the model using flax.linen. After that, during inference, we use either `flax.linen` or `flax.nnx`. When using `flax.nnx`, we convert the trained model from `flax.linen` to `flax.nnx`, using `wrappers.convert_flax_linen_module_with_params_to_nnx`.\n",
        "\n",
        "This colab highlights the flexibility of our library during inference."
      ],
      "metadata": {
        "id": "K43uX-gRu1O8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLydYq_yuo2I"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# Common modules\n",
        "################################################################################\n",
        "\n",
        "import dataclasses\n",
        "import functools\n",
        "from etils import ecolab\n",
        "import flax.linen as nn\n",
        "import grain.python as pygrain\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optax\n",
        "import tensorflow_datasets as tfds\n",
        "import tqdm\n",
        "\n",
        "################################################################################\n",
        "# Hackable diffusion modules\n",
        "################################################################################\n",
        "\n",
        "cell_autoreload = True  # @param{type: \"boolean\"}\n",
        "\n",
        "with ecolab.adhoc(\n",
        "    reload=[\"hackable_diffusion\"],\n",
        "    invalidate=False,\n",
        "    cell_autoreload=cell_autoreload,\n",
        "):\n",
        "  from hackable_diffusion import hd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diffusion_network = hd.diffusion_network\n",
        "time_sampling = hd.time_sampling\n",
        "gaussian = hd.corruption.gaussian\n",
        "schedules = hd.corruption.schedules\n",
        "arch_typing = hd.architecture.arch_typing\n",
        "conditioning_encoder = hd.architecture.conditioning_encoder\n",
        "unet = hd.architecture.unet\n",
        "wrappers = hd.inference.wrappers\n",
        "diffusion_inference = hd.inference.diffusion_inference\n",
        "gaussian_loss = hd.loss.gaussian\n",
        "time_scheduling = hd.sampling.time_scheduling\n",
        "sampling = hd.sampling.sampling\n",
        "gaussian_step_sampler = hd.sampling.gaussian_step_sampler"
      ],
      "metadata": {
        "id": "LvOf7PdOAYFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare MNIST data"
      ],
      "metadata": {
        "id": "_e8om2QJvWDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create py-grain data structures for convenient batching and loading.\n",
        "\n",
        "MNIST data is $28 \\times 28 \\times 3$ (the images are scaled between $-1.0$ and $1.0$)."
      ],
      "metadata": {
        "id": "kAeUl5SQpdGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclasses.dataclass(frozen=True)\n",
        "class PreprocessExample(pygrain.MapTransform):\n",
        "  \"\"\"Preprocesses an example.\"\"\"\n",
        "\n",
        "  def map(self, x: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
        "    \"\"\"Rescales image values to [-1, 1] and converts labels to int32.\"\"\"\n",
        "\n",
        "    image = x['image'].astype(np.float32) / 127.5 - 1.0\n",
        "    image = np.reshape(image, (28, 28, 1))\n",
        "    image = np.tile(image, (1, 1, 3))\n",
        "\n",
        "    return {\n",
        "        'data': image,\n",
        "        'label': np.int32(x['label']),\n",
        "    }\n",
        "\n",
        "\n",
        "def mnist_dataset(batch_size, train) -> pygrain.DataLoader:\n",
        "  loader = pygrain.load(\n",
        "      source=tfds.data_source(name='mnist', split='all'),\n",
        "      shuffle=True if train else False,\n",
        "      shard_options=pygrain.ShardByJaxProcess(drop_remainder=True),\n",
        "      transformations=[PreprocessExample()],\n",
        "      batch_size=batch_size,\n",
        "      drop_remainder=True,\n",
        "      seed=0,\n",
        "  )\n",
        "  return loader"
      ],
      "metadata": {
        "id": "790dD3J2o5Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_plot_images = next(iter(mnist_dataset(64, train=False)))['data']\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(mnist_plot_images[:64], axes.flatten()):\n",
        "  ax.imshow(img)\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6nYspS7cpM6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define all diffusion model modules"
      ],
      "metadata": {
        "id": "OWP4NiIfMBde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Noise process"
      ],
      "metadata": {
        "id": "xN5dcCQhLRSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Rectified Flow noise schedule $x_{t} = (1-t) x_0 + t \\epsilon$, $\\epsilon \\sim N(0, I)$"
      ],
      "metadata": {
        "id": "odHo5roqFfYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schedule = schedules.RFSchedule()\n",
        "process = gaussian.GaussianProcess(schedule=schedule)"
      ],
      "metadata": {
        "id": "doItCfTdLQvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize noise process"
      ],
      "metadata": {
        "id": "SDjo5LRSLskH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_noises = 7\n",
        "fig, axes = plt.subplots(\n",
        "    ncols=num_noises, figsize=(num_noises * 4, 4), sharex=True, sharey=True\n",
        ")\n",
        "\n",
        "corrupt_rng = jax.random.PRNGKey(10)\n",
        "idx = 0\n",
        "for time in jnp.linspace(1e-3, 1.0 - 1e-3, num=num_noises):\n",
        "  xt, _ = process.corrupt(\n",
        "      key=corrupt_rng,\n",
        "      x0=jnp.array(mnist_plot_images),\n",
        "      time=jnp.ones((1,)) * time,\n",
        "  )\n",
        "  ax = axes[idx]\n",
        "  ax.imshow(xt[0])\n",
        "  ax.axis('off')\n",
        "  ax.set_title(f'Time = {time}')\n",
        "  idx += 1"
      ],
      "metadata": {
        "id": "12mocRWzLuAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define diffusion network backbone\n",
        "\n",
        "First, we define diffusion backbone -- an architecture which takex `x` and `conditioning_embeddings`, as well as `is_training` and returns the same type as `x`.\n",
        "\n",
        "Here, we use a small version of `Unet`."
      ],
      "metadata": {
        "id": "8fiOvaxNMOh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = unet.Unet(\n",
        "    base_channels=32,\n",
        "    channels_multiplier=(1, 2, 2),\n",
        "    num_residual_blocks=(2, 2, 2),\n",
        "    downsample_method=arch_typing.DownsampleType.AVG_POOL,\n",
        "    upsample_method=arch_typing.UpsampleType.NEAREST,\n",
        "    dropout_rate=(0.0, 0.0, 0.2),\n",
        "    bottleneck_dropout_rate=0.2,\n",
        "    self_attention_bool=(False, False, False),\n",
        "    cross_attention_bool=(False, False, False),\n",
        "    attention_normalize_qk=False,\n",
        "    attention_use_rope=False,\n",
        "    attention_rope_position_type=arch_typing.RoPEPositionType.SQUARE,\n",
        "    attention_num_heads=8,\n",
        "    attention_head_dim=-1,\n",
        "    normalization_type=arch_typing.NormalizationType.RMS_NORM,\n",
        "    normalization_num_groups=None,\n",
        "    zero_init_output=False,\n",
        "    activation='gelu',\n",
        "    skip_connection_method=arch_typing.SkipConnectionMethod.NORMALIZED_ADD,\n",
        ")"
      ],
      "metadata": {
        "id": "11x4iOOprtTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define conditioning logic"
      ],
      "metadata": {
        "id": "ARc5ksUEHG0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we define the conditioning embedders as well as the time encoder. The conditioning encoder processes each conditioning (in the case of MNIST data, each batch comes with its label (`label`)).\n",
        "\n",
        "The conditioning encoder is a dictionary with key `label` (and here the value is a `nn.Module` which is given by a simple `LabelEmbedding` module). If you want to train a purely unconditional model, set `conditioning_embedders = {}`.\n",
        "\n"
      ],
      "metadata": {
        "id": "fqGG4Co-HD1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# Conditional diffusion.\n",
        "################################################################################\n",
        "\n",
        "conditioning_embedders = {\n",
        "    'label': conditioning_encoder.LabelEmbedder(\n",
        "        num_classes=10,\n",
        "        num_features=256,\n",
        "        conditioning_key='label',\n",
        "    )\n",
        "}\n",
        "\n",
        "encoder = conditioning_encoder.ConditioningEncoder(\n",
        "    time_embedder=conditioning_encoder.SinusoidalTimeEmbedder(\n",
        "        activation='gelu', embedding_dim=256, num_features=256\n",
        "    ),\n",
        "    conditioning_embedders=conditioning_embedders,\n",
        "    embedding_merging_method=arch_typing.EmbeddingMergeMethod.SUM,\n",
        "    conditioning_rules={\n",
        "        'time': arch_typing.ConditioningMechanism.ADAPTIVE_NORM,\n",
        "        'label': arch_typing.ConditioningMechanism.ADAPTIVE_NORM,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "pDQv0FEEHFj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting all together into diffusion network"
      ],
      "metadata": {
        "id": "E9Cy-hgrH7gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = diffusion_network.DiffusionNetwork(\n",
        "    backbone_network=backbone,\n",
        "    conditioning_encoder=encoder,\n",
        "    prediction_type='x0',\n",
        ")"
      ],
      "metadata": {
        "id": "7EUVYISMH9bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model visualization"
      ],
      "metadata": {
        "id": "5rwfPG_EtTS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_depth = 2  # @param {type: \"integer\"}\n",
        "\n",
        "tabulate_fn = nn.tabulate(\n",
        "    network,\n",
        "    jax.random.PRNGKey(42),\n",
        "    depth=summary_depth,\n",
        "    console_kwargs={\"force_jupyter\": True, \"soft_wrap\": True},\n",
        ")\n",
        "\n",
        "dummy_time = jnp.ones((1,))\n",
        "dummy_xt = jnp.ones((1, 28, 28, 3))\n",
        "dummy_conditioning = {\"label\": jnp.ones((1,)).astype(jnp.int32)}\n",
        "\n",
        "print(\n",
        "    tabulate_fn(\n",
        "        dummy_time,\n",
        "        dummy_xt,\n",
        "        dummy_conditioning,\n",
        "        is_training=False,\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "LvX6WLQGN1cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define time sampler, optimizer and loss function\n",
        "\n",
        "The time is sampled uniformly in the interval $[\\epsilon,1 - \\epsilon]$.\n",
        "\n",
        "The loss is simply the $\\ell_2$ loss."
      ],
      "metadata": {
        "id": "emGbkd8vMWyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_sampler = time_sampling.UniformTimeSampler(safety_epsilon=1e-3)\n",
        "\n",
        "optimizer = optax.chain(\n",
        "    optax.clip_by_global_norm(max_norm=1.0),\n",
        "    optax.scale_by_adam(b1=0.9, b2=0.999, eps=1e-8),\n",
        "    optax.scale_by_schedule(optax.constant_schedule(value=5e-4)),\n",
        "    optax.scale(-1.0),\n",
        ")\n",
        "\n",
        "loss_fn = gaussian_loss.NoWeightGaussianLoss()"
      ],
      "metadata": {
        "id": "1Y-S0iHuIa9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the parameters loss function and gradient function\n",
        "\n",
        "Here we define the loss function as well as gradient function to be dependent on NN parameters. This is needed for training the neural network."
      ],
      "metadata": {
        "id": "qYyGqTogMdp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def params_loss_fn(params, x0, conditioning, rng):\n",
        "  time_rng, corrupt_rng = jax.random.split(rng, 2)\n",
        "  time = time_sampler(key=time_rng, data_spec=x0)\n",
        "  xt, targets = process.corrupt(key=corrupt_rng, x0=x0, time=time)\n",
        "  output = network.apply(\n",
        "      {'params': params},\n",
        "      time=time,\n",
        "      xt=xt,\n",
        "      conditioning=conditioning,\n",
        "      is_training=True,\n",
        "      rngs={'dropout': rng},\n",
        "  )\n",
        "  out = jnp.mean(loss_fn(preds=output, targets=targets, time=time))\n",
        "  return out, {'loss': out}\n",
        "\n",
        "\n",
        "grad_fn = jax.jit(jax.grad(params_loss_fn, has_aux=True))"
      ],
      "metadata": {
        "id": "Pun40gVLtsf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrapping the whole update into `update_fn` since it makes the updates much faster"
      ],
      "metadata": {
        "id": "QZeLtgeGR8uI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def update_fn(params, opt_state, x0, conditioning, rng):\n",
        "  grads, metrics = grad_fn(params, x0, conditioning, rng)\n",
        "  updates, opt_state = optimizer.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state, metrics"
      ],
      "metadata": {
        "id": "_uXRZ2hSRjEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "Training the model should take less than 10 minutes."
      ],
      "metadata": {
        "id": "e3ebC1hxIcVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nepochs = 10\n",
        "batch_size = 256\n",
        "epoch_size = 60000 // batch_size"
      ],
      "metadata": {
        "id": "oRqMSxTmIeYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "\n",
        "params = network.initialize_variables(\n",
        "    input_shape=(1, 28, 28, 3),\n",
        "    conditioning_shape={'label': (1,)},\n",
        "    key=rng,\n",
        "    is_training=True,\n",
        ")['params']\n",
        "\n",
        "opt_state = optimizer.init(params)\n",
        "\n",
        "train_iter = iter(mnist_dataset(batch_size, train=True))\n",
        "\n",
        "losses = []\n",
        "for epoch in tqdm.tqdm(range(1, nepochs + 1)):\n",
        "  epoch_loss = steps = 0\n",
        "  for i in range(epoch_size):\n",
        "    # Read batch of data\n",
        "    batch = next(train_iter)\n",
        "    x0 = batch['data']\n",
        "    conditioning = {'label': batch['label']}\n",
        "    # Make the parameters update\n",
        "    rng, _ = jax.random.split(rng)\n",
        "    params, opt_state, metrics = update_fn(\n",
        "        params, opt_state, x0, conditioning, rng\n",
        "    )\n",
        "    epoch_loss += metrics['loss']\n",
        "    steps += 1\n",
        "  print(f'Epoch = {epoch}, Cumulative epoch loss = {epoch_loss}')\n",
        "  losses.append(epoch_loss)"
      ],
      "metadata": {
        "id": "boqKlkENt4aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "metadata": {
        "id": "Zt9AlILeuyQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9dX8jwMpfuv"
      },
      "source": [
        "## It's inference time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qij2alwWphef"
      },
      "source": [
        "Create `nnx` network which will be used for inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nnx_network = wrappers.convert_flax_linen_module_with_params_to_nnx(\n",
        "    linen_module=network,\n",
        "    restored_linen_params=params,\n",
        "    time=dummy_time,\n",
        "    xt=dummy_xt,\n",
        "    conditioning=dummy_conditioning,\n",
        "    is_training=False,\n",
        ")"
      ],
      "metadata": {
        "id": "0zFQfAlc89Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define flax.linen inference function as well as nnx inference function"
      ],
      "metadata": {
        "id": "XdKJIJMxAwA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_fn_linen = diffusion_inference.GuidedDiffusionInferenceFn(\n",
        "    base_inference_fn=wrappers.FlaxLinenInferenceFn(\n",
        "        network=network, params=params\n",
        "    )\n",
        ")\n",
        "inference_fn_nnx = wrappers.FlaxNNXInferenceFn(nnx_network=nnx_network)"
      ],
      "metadata": {
        "id": "DGs-KVkmvFCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose your inference function"
      ],
      "metadata": {
        "id": "KIncrBcqA3T6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_nnx = True  # @param\n",
        "\n",
        "if use_nnx:\n",
        "  inference_fn = inference_fn_nnx\n",
        "  print('Using Flax.nnx for inference')\n",
        "else:\n",
        "  inference_fn = inference_fn_linen\n",
        "  print('Using Flax.linen for inference')"
      ],
      "metadata": {
        "id": "edLK00szA4iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference with `flax.linen`\n"
      ],
      "metadata": {
        "id": "tYAxOKnJF6Rq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampler -- time_schedule, stepper and sampler itself"
      ],
      "metadata": {
        "id": "BcVHlXAhPuY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_sampling_steps = 100  # Number of denoising steps\n",
        "stochasticity_level = 1.0  # Stochasticity coefficient in DDIM\n",
        "\n",
        "time_schedule = time_scheduling.UniformTimeSchedule()\n",
        "stepper = gaussian_step_sampler.DDIMStep(\n",
        "    corruption_process=process, stoch_coeff=stochasticity_level\n",
        ")\n",
        "\n",
        "sampler = sampling.DiffusionSampler(\n",
        "    time_schedule=time_schedule, stepper=stepper, num_steps=num_sampling_steps\n",
        ")\n",
        "sampler = functools.partial(sampler, inference_fn=inference_fn_linen)\n",
        "sampler = jax.jit(jax.experimental.checkify.checkify(sampler))"
      ],
      "metadata": {
        "id": "sLpq6yoWw7rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling the data\n",
        "\n",
        "* First, we sample the data taking the conditioning from a batch of data, allowing to approximate $p(x_0)$\n",
        "\n",
        "* Second, we sample data with a given label, allowing to sample $p(x_0 | c)$"
      ],
      "metadata": {
        "id": "yTHo_XNGP0lU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_w_9y8OW8nz"
      },
      "outputs": [],
      "source": [
        "num_samples = 64\n",
        "data_spec = jnp.ones((num_samples, 28, 28, 3), dtype=jnp.float32)\n",
        "specific_label = 5\n",
        "\n",
        "eval_iter = iter(mnist_dataset(num_samples, train=False))\n",
        "eval_data = next(eval_iter)\n",
        "\n",
        "################################################################################\n",
        "# Sample conditionally using dataset\n",
        "################################################################################\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "initial_noise = process.sample_from_invariant(key=key, data_spec=data_spec)\n",
        "conditioning = {\"label\": eval_data[\"label\"]}\n",
        "_, (out_cond, _) = sampler(\n",
        "    rng=key, initial_noise=initial_noise, conditioning=conditioning\n",
        ")\n",
        "\n",
        "################################################################################\n",
        "# Sample from a given label\n",
        "################################################################################\n",
        "\n",
        "key = jax.random.PRNGKey(1)\n",
        "initial_noise = process.sample_from_invariant(key=key, data_spec=data_spec)\n",
        "conditioning = {\n",
        "    \"label\": jnp.ones((num_samples,)).astype(jnp.int32) * specific_label\n",
        "}\n",
        "_, (out_label, _) = sampler(\n",
        "    rng=key, initial_noise=initial_noise, conditioning=conditioning\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize true dataset"
      ],
      "metadata": {
        "id": "ap-N0ng3VNfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_mnist_plot_images = eval_data['data']\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(cur_mnist_plot_images[:64], axes.flatten()):\n",
        "  ax.imshow(img)\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GpNNzUxaVP41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize samples from $p(x_0)$"
      ],
      "metadata": {
        "id": "DmsEJpC2VQ1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_mnist_plot_images = out_cond.xt\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(cur_mnist_plot_images[:64], axes.flatten()):\n",
        "  ax.imshow(img)\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q7dxWHBPVPTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize samples from $p(x_0 | c)$"
      ],
      "metadata": {
        "id": "PEsoaSmsVVuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_mnist_plot_images = out_label.xt\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(cur_mnist_plot_images[:64], axes.flatten()):\n",
        "  ax.imshow(img)\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A4ljuY8cVVuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_with_flax_linen = (out_cond.xt, out_label.xt)"
      ],
      "metadata": {
        "id": "xui2t29iHq1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference with `flax.nnx`\n"
      ],
      "metadata": {
        "id": "plQLNPezGDby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampler -- time_schedule, stepper and sampler itself"
      ],
      "metadata": {
        "id": "KkeCwLvUGDby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_sampling_steps = 100  # Number of denoising steps\n",
        "stochasticity_level = 1.0  # Stochasticity coefficient in DDIM\n",
        "\n",
        "time_schedule = time_scheduling.UniformTimeSchedule()\n",
        "stepper = gaussian_step_sampler.DDIMStep(\n",
        "    corruption_process=process, stoch_coeff=stochasticity_level\n",
        ")\n",
        "\n",
        "sampler = sampling.DiffusionSampler(\n",
        "    time_schedule=time_schedule, stepper=stepper, num_steps=num_sampling_steps\n",
        ")\n",
        "sampler = functools.partial(sampler, inference_fn=inference_fn_nnx)\n",
        "sampler = jax.jit(jax.experimental.checkify.checkify(sampler))"
      ],
      "metadata": {
        "id": "dZ7YT4pwGDbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling the data\n",
        "\n",
        "* First, we sample the data taking the conditioning from a batch of data, allowing to approximate $p(x_0)$\n",
        "\n",
        "* Second, we sample data with a given label, allowing to sample $p(x_0 | c)$"
      ],
      "metadata": {
        "id": "OKWODLXcGDbz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKxzcsIfGDbz"
      },
      "outputs": [],
      "source": [
        "num_samples = 64\n",
        "data_spec = jnp.ones((num_samples, 28, 28, 3), dtype=jnp.float32)\n",
        "specific_label = 5\n",
        "\n",
        "eval_iter = iter(mnist_dataset(num_samples, train=False))\n",
        "eval_data = next(eval_iter)\n",
        "\n",
        "################################################################################\n",
        "# Sample conditionally using dataset\n",
        "################################################################################\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "initial_noise = process.sample_from_invariant(key=key, data_spec=data_spec)\n",
        "conditioning = {\"label\": eval_data[\"label\"]}\n",
        "_, (out_cond, _) = sampler(\n",
        "    rng=key, initial_noise=initial_noise, conditioning=conditioning\n",
        ")\n",
        "\n",
        "################################################################################\n",
        "# Sample from a given label\n",
        "################################################################################\n",
        "\n",
        "key = jax.random.PRNGKey(1)\n",
        "initial_noise = process.sample_from_invariant(key=key, data_spec=data_spec)\n",
        "conditioning = {\n",
        "    \"label\": jnp.ones((num_samples,)).astype(jnp.int32) * specific_label\n",
        "}\n",
        "_, (out_label, _) = sampler(\n",
        "    rng=key, initial_noise=initial_noise, conditioning=conditioning\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize true dataset"
      ],
      "metadata": {
        "id": "2C8iOdo1GDbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_mnist_plot_images = eval_data['data']\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(cur_mnist_plot_images[:64], axes.flatten()):\n",
        "  ax.imshow(img)\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AIyl6sowGDbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize samples from $p(x_0)$"
      ],
      "metadata": {
        "id": "xYBWOWnHGDbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_mnist_plot_images = out_cond.xt\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(cur_mnist_plot_images[:64], axes.flatten()):\n",
        "  ax.imshow(img)\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "84pmZodFGDbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize samples from $p(x_0 | c)$"
      ],
      "metadata": {
        "id": "sOo5bUq_GDbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_mnist_plot_images = out_label.xt\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(cur_mnist_plot_images[:64], axes.flatten()):\n",
        "  ax.imshow(img)\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zYPe3S0UGDbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_with_flax_nnx = (out_cond.xt, out_label.xt)"
      ],
      "metadata": {
        "id": "2MS20nJTHk-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check that the outputs of both procedures are identical"
      ],
      "metadata": {
        "id": "uOUrs--FHjiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_cond_xt_nnx, out_label_xt_nnx = outputs_with_flax_nnx\n",
        "out_cond_xt_linen, out_label_xt_linen = outputs_with_flax_linen"
      ],
      "metadata": {
        "id": "Ti9Lp7cdHwCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(jnp.mean(jnp.square(out_cond_xt_nnx - out_cond_xt_linen)))\n",
        "print(jnp.mean(jnp.square(out_label_xt_nnx - out_label_xt_linen)))"
      ],
      "metadata": {
        "id": "4aR7paxhH8Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vh32tt3HICq_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/dm_python:dm_notebook3",
        "kind": "private"
      },
      "collapsed_sections": [
        "tYAxOKnJF6Rq",
        "plQLNPezGDby"
      ]
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
