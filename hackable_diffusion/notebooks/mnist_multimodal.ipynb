{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training Multimodal MNIST ðŸš€\n",
        "\n",
        "In this colab we showcase how to train a diffusion model on MNIST dataset. This\n",
        "colab can run on any colab backend."
      ],
      "metadata": {
        "id": "K43uX-gRu1O8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLydYq_yuo2I"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# Common modules\n",
        "################################################################################\n",
        "\n",
        "import dataclasses\n",
        "import functools\n",
        "from typing import Protocol\n",
        "from etils import ecolab\n",
        "from flax import linen as nn\n",
        "import grain.python as pygrain\n",
        "import jax\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jaxtyping import PyTree  # pylint: disable=g-multiple-import,g-importing-member\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optax\n",
        "import tensorflow_datasets as tfds\n",
        "import tqdm\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Hackable diffusion modules\n",
        "################################################################################\n",
        "\n",
        "cell_autoreload = True  # @param{type: \"boolean\"}\n",
        "\n",
        "with ecolab.adhoc(\n",
        "    reload=[\"hackable_diffusion\"],\n",
        "    invalidate=False,\n",
        "    cell_autoreload=cell_autoreload,\n",
        "):\n",
        "  from hackable_diffusion import hd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diffusion_network = hd.diffusion_network\n",
        "hd_typing = hd.hd_typing\n",
        "utils = hd.utils\n",
        "time_sampling = hd.time_sampling\n",
        "base_process = hd.corruption.base\n",
        "gaussian_process = hd.corruption.gaussian\n",
        "discrete_process = hd.corruption.discrete\n",
        "schedules = hd.corruption.schedules\n",
        "arch_typing = hd.architecture.arch_typing\n",
        "conditioning_encoder = hd.architecture.conditioning_encoder\n",
        "discrete_backbone = hd.architecture.discrete\n",
        "unet = hd.architecture.unet\n",
        "diffusion_inference = hd.inference.diffusion_inference\n",
        "wrappers = hd.inference.wrappers\n",
        "gaussian_loss = hd.loss.gaussian\n",
        "discrete_loss = hd.loss.discrete\n",
        "base_loss = hd.loss.base\n",
        "time_scheduling = hd.sampling.time_scheduling\n",
        "sampling = hd.sampling.sampling\n",
        "gaussian_step_sampler = hd.sampling.gaussian_step_sampler\n",
        "discrete_step_sampler = hd.sampling.discrete_step_sampler\n",
        "base_sampler = hd.sampling.base"
      ],
      "metadata": {
        "id": "gEOYTEggXyzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare MNIST data"
      ],
      "metadata": {
        "id": "_e8om2QJvWDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create py-grain data structures for convenient batching and loading.\n",
        "\n",
        "MNIST data is $28 \\times 28 \\times 3$ (the images are scaled between $-1.0$ and\n",
        "$1.0$)."
      ],
      "metadata": {
        "id": "kAeUl5SQpdGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclasses.dataclass(frozen=True)\n",
        "class PreprocessExample(pygrain.MapTransform):\n",
        "  \"\"\"Preprocesses an example.\"\"\"\n",
        "\n",
        "  def map(self, x: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
        "    \"\"\"Rescales image values to [-1, 1] and converts labels to int32.\"\"\"\n",
        "\n",
        "    image = x['image']\n",
        "\n",
        "    image_discrete = image.astype(np.int32)\n",
        "    image_discrete = np.reshape(image_discrete, (28, 28, 1))\n",
        "    # We add additional dimension for the tokens\n",
        "    image_discrete = np.expand_dims(image_discrete, axis=-1)\n",
        "\n",
        "    image_continuous = image.astype(np.float32) / 127.5 - 1.0\n",
        "    image_continuous = np.reshape(image_continuous, (28, 28, 1))\n",
        "    image_continuous = np.tile(image_continuous, (1, 1, 3))\n",
        "\n",
        "    return {\n",
        "        'data': {\n",
        "            'data_continuous': image_continuous,\n",
        "            'data_discrete': image_discrete,\n",
        "        },\n",
        "        'label': np.int32(x['label']),\n",
        "    }\n",
        "\n",
        "\n",
        "def mnist_dataset(batch_size, train) -> pygrain.DataLoader:\n",
        "  loader = pygrain.load(\n",
        "      source=tfds.data_source(name='mnist', split='all'),\n",
        "      shuffle=True if train else False,\n",
        "      shard_options=pygrain.ShardByJaxProcess(drop_remainder=True),\n",
        "      transformations=[PreprocessExample()],\n",
        "      batch_size=batch_size,\n",
        "      drop_remainder=True,\n",
        "      seed=0,\n",
        "  )\n",
        "  return loader"
      ],
      "metadata": {
        "id": "790dD3J2o5Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by plotting both the discrete and continuous images."
      ],
      "metadata": {
        "id": "YjpBvteHWLpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(mnist_dataset(64, train=False)))\n",
        "mnist_plot_images_continuous = batch['data']['data_continuous']\n",
        "\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(mnist_plot_images_continuous[:64], axes.flatten()):\n",
        "  ax.imshow(img)\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6nYspS7cpM6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_plot_images_discrete = batch['data']['data_discrete']\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(mnist_plot_images_discrete[:64], axes.flatten()):\n",
        "  ax.imshow(img[:, :, :, 0])\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oWTTNofHWWw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(linewidth=160)\n",
        "mnist_plot_images_discrete[0][:, :, 0, 0]"
      ],
      "metadata": {
        "id": "axdST7iTWi07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define all diffusion model modules"
      ],
      "metadata": {
        "id": "OWP4NiIfMBde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Noise process"
      ],
      "metadata": {
        "id": "xN5dcCQhLRSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Rectified Flow noise schedule $x_{t} = (1-t) x_0 + t \\epsilon$, $\\epsilon\n",
        "\\sim N(0, I)$ for the continuous data and a masking schedule for the discrete\n",
        "data."
      ],
      "metadata": {
        "id": "odHo5roqFfYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schedule_continuous = schedules.RFSchedule()\n",
        "process_continuous = gaussian_process.GaussianProcess(schedule=schedule_continuous)"
      ],
      "metadata": {
        "id": "doItCfTdLQvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schedule_discrete = schedules.CosineDiscreteSchedule()\n",
        "process_discrete = discrete_process.CategoricalProcess.masking_process(\n",
        "    schedule=schedule_discrete, num_categories=256\n",
        ")"
      ],
      "metadata": {
        "id": "w7NBfhWKYBr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process = base_process.NestedProcess(\n",
        "    processes={\n",
        "        'data_continuous': process_continuous,\n",
        "        'data_discrete': process_discrete,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "hEGZcNdQYOg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize noise process"
      ],
      "metadata": {
        "id": "SDjo5LRSLskH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_noises = 7\n",
        "fig, axes = plt.subplots(\n",
        "    ncols=num_noises, figsize=(num_noises * 4, 4), sharex=True, sharey=True\n",
        ")\n",
        "\n",
        "x0 = jax.tree.map(lambda x: jnp.array(x), batch['data'])\n",
        "\n",
        "corrupt_rng = jax.random.PRNGKey(10)\n",
        "idx = 0\n",
        "for time in jnp.linspace(1e-3, 1.0 - 1e-3, num=num_noises):\n",
        "  time_dict = {\n",
        "      'data_continuous': jnp.ones((1,)) * time,\n",
        "      'data_discrete': jnp.ones((1,)) * time,\n",
        "  }\n",
        "  xt, _ = process.corrupt(key=corrupt_rng, x0=x0, time=time_dict)\n",
        "  ax = axes[idx]\n",
        "  ax.imshow(xt['data_continuous'][0])\n",
        "  ax.axis('off')\n",
        "  ax.set_title(f'Time = {time_dict['data_continuous'][0].squeeze().item()}')\n",
        "  idx += 1"
      ],
      "metadata": {
        "id": "12mocRWzLuAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_noises = 7\n",
        "fig, axes = plt.subplots(\n",
        "    ncols=num_noises, figsize=(num_noises * 4, 4), sharex=True, sharey=True\n",
        ")\n",
        "\n",
        "x0 = jax.tree.map(lambda x: jnp.array(x), batch['data'])\n",
        "\n",
        "corrupt_rng = jax.random.PRNGKey(10)\n",
        "idx = 0\n",
        "for time in jnp.linspace(1e-3, 1.0 - 1e-3, num=num_noises):\n",
        "  time_dict = {\n",
        "      'data_continuous': jnp.ones((1,)) * time,\n",
        "      'data_discrete': jnp.ones((1,)) * time,\n",
        "  }\n",
        "  xt, _ = process.corrupt(key=corrupt_rng, x0=x0, time=time_dict)\n",
        "  ax = axes[idx]\n",
        "  ax.imshow(xt['data_discrete'][0, ..., 0])\n",
        "  ax.axis('off')\n",
        "  ax.set_title(f'Time = {time_dict['data_discrete'][0].squeeze().item()}')\n",
        "  idx += 1"
      ],
      "metadata": {
        "id": "RUDiVpWobFe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define diffusion network backbone\n",
        "\n",
        "First, we define diffusion backbone -- an architecture which takex `x` and\n",
        "`conditioning_embeddings`, as well as `is_training` and returns the same type as\n",
        "`x`.\n",
        "\n",
        "Here, we use a small version of `Unet`."
      ],
      "metadata": {
        "id": "8fiOvaxNMOh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_backbone = unet.Unet(\n",
        "    base_channels=32,\n",
        "    channels_multiplier=(1, 2, 2),\n",
        "    num_residual_blocks=(2, 2, 2),\n",
        "    downsample_method=arch_typing.DownsampleType.AVG_POOL,\n",
        "    upsample_method=arch_typing.UpsampleType.NEAREST,\n",
        "    dropout_rate=(0.0, 0.0, 0.2),\n",
        "    bottleneck_dropout_rate=0.2,\n",
        "    self_attention_bool=(False, False, False),\n",
        "    cross_attention_bool=(False, False, False),\n",
        "    attention_normalize_qk=False,\n",
        "    attention_use_rope=False,\n",
        "    attention_rope_position_type=arch_typing.RoPEPositionType.SQUARE,\n",
        "    attention_num_heads=8,\n",
        "    attention_head_dim=-1,\n",
        "    normalization_type=arch_typing.NormalizationType.RMS_NORM,\n",
        "    normalization_num_groups=None,\n",
        "    zero_init_output=False,\n",
        "    activation='gelu',\n",
        "    skip_connection_method=arch_typing.SkipConnectionMethod.NORMALIZED_ADD,\n",
        ")\n",
        "\n",
        "token_embedder = discrete_backbone.TokenEmbedder(\n",
        "    process_num_categories=process.processes[\n",
        "        'data_discrete'\n",
        "    ].process_num_categories,\n",
        "    embedding_dim=32,\n",
        "    adapt_to_image_like_data=True,\n",
        ")\n",
        "embedder = {'data_continuous': None, 'data_discrete': token_embedder}\n",
        "token_projector = discrete_backbone.DenseTokenProjector(\n",
        "    num_categories=process.processes['data_discrete'].num_categories,\n",
        "    embedding_dim=32,\n",
        "    adapt_to_image_like_data=True,\n",
        ")\n",
        "projector = {'data_continuous': None, 'data_discrete': token_projector}"
      ],
      "metadata": {
        "id": "11x4iOOprtTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Multimodal conditional backbone"
      ],
      "metadata": {
        "id": "5an_rkxzR-lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Backbones for multimodal data.\"\"\"\n",
        "\n",
        "################################################################################\n",
        "# MARK: Type Aliases\n",
        "################################################################################\n",
        "\n",
        "Dtype = jax.typing.DTypeLike\n",
        "Float = hd_typing.Float\n",
        "DataArray = hd_typing.DataArray\n",
        "DataTree = hd_typing.DataTree\n",
        "ConditionalBackbone = arch_typing.ConditionalBackbone\n",
        "BaseTokenEmbedder = discrete_backbone.BaseTokenEmbedder\n",
        "BaseTokenProjector = discrete_backbone.BaseTokenProjector\n",
        "\n",
        "################################################################################\n",
        "# MARK: Multimodal\n",
        "################################################################################\n",
        "\n",
        "\n",
        "class BaseVectorizer(Protocol):\n",
        "  \"\"\"Vectorizer interface.\"\"\"\n",
        "\n",
        "  def vectorize(self, x: DataTree) -> DataArray:\n",
        "    \"\"\"Vectorizes the input data.\"\"\"\n",
        "    ...\n",
        "\n",
        "  def unvectorize(self, original: DataTree, x: DataArray) -> DataTree:\n",
        "    \"\"\"Unvectorizes the input data.\"\"\"\n",
        "    ...\n",
        "\n",
        "\n",
        "class ChannelVectorizer(BaseVectorizer):\n",
        "  \"\"\"Vectorizer that uses channels to vectorize the data.\"\"\"\n",
        "\n",
        "  def vectorize(self, x: DataTree) -> DataArray:\n",
        "    leaves, _ = jax.tree_util.tree_flatten(x)\n",
        "    return jnp.concatenate(leaves, axis=-1)\n",
        "\n",
        "  def unvectorize(self, original: DataTree, x: DataArray) -> DataTree:\n",
        "    leaves, treedef = jax.tree_util.tree_flatten(original)\n",
        "    split_sizes = [leaf.shape[-1] for leaf in leaves]\n",
        "    split_indices = np.cumsum(np.array(split_sizes[:-1]))\n",
        "    # numpy is needed here to get a Concrete value\n",
        "    split_leaves = jnp.split(x, split_indices, axis=-1)\n",
        "    return jax.tree_util.tree_unflatten(treedef, split_leaves)\n",
        "\n",
        "\n",
        "class ConditionalMultimodalBackbone(ConditionalBackbone):\n",
        "  \"\"\"Conditional multimodal backbone for diffusion models.\n",
        "\n",
        "  Attributes:\n",
        "    base_backbone: The base backbone to use for the discrete model. Can be any\n",
        "      conditionl backbone such as MLP or UNet.\n",
        "    token_embedder: The token embedder to use for the discrete model.\n",
        "  \"\"\"\n",
        "\n",
        "  base_backbone: ConditionalBackbone\n",
        "  embedder: PyTree[BaseTokenEmbedder | None]\n",
        "  projector: PyTree[BaseTokenProjector | None]\n",
        "  vectorizer: BaseVectorizer\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(\n",
        "      self,\n",
        "      x: DataTree,\n",
        "      conditioning_embeddings: dict[str, Float['batch ...']],\n",
        "      is_training: bool,\n",
        "  ) -> DataTree:\n",
        "\n",
        "    # Embed the tokens.\n",
        "    token_embeddings = jax.tree.map(\n",
        "        lambda embedder, x: embedder(x, is_training=is_training)\n",
        "        if embedder is not None\n",
        "        else x,\n",
        "        self.embedder.unfreeze(),\n",
        "        x,\n",
        "        is_leaf=lambda x: x is None,\n",
        "    )\n",
        "\n",
        "    embeddings = self.vectorizer.vectorize(x=token_embeddings)\n",
        "\n",
        "    # Output the result of the base backbone.\n",
        "    backbone_outputs = self.base_backbone(\n",
        "        x=embeddings,\n",
        "        conditioning_embeddings=conditioning_embeddings,\n",
        "        is_training=is_training,\n",
        "    )\n",
        "\n",
        "    # Unvectorize the result of the base backbone.\n",
        "    output = self.vectorizer.unvectorize(\n",
        "        original=token_embeddings,\n",
        "        x=backbone_outputs,\n",
        "    )\n",
        "\n",
        "    output = jax.tree.map(\n",
        "        lambda projector, x: projector(x, is_training=is_training)\n",
        "        if projector is not None\n",
        "        else x,\n",
        "        self.projector.unfreeze(),\n",
        "        output,\n",
        "        is_leaf=lambda x: x is None,\n",
        "    )\n",
        "\n",
        "    output = utils.optional_bf16_to_fp32(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "qdwezd9RSQKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = ChannelVectorizer()\n",
        "\n",
        "backbone = ConditionalMultimodalBackbone(\n",
        "    base_backbone=base_backbone,\n",
        "    embedder=embedder,\n",
        "    projector=projector,\n",
        "    vectorizer=vectorizer,\n",
        ")"
      ],
      "metadata": {
        "id": "uSxtrN_CTqND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define conditioning logic"
      ],
      "metadata": {
        "id": "ARc5ksUEHG0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we define the conditioning embedders as well as the time encoder. The\n",
        "conditioning encoder processes each conditioning (in the case of MNIST data,\n",
        "each batch comes with its label (`label`)).\n",
        "\n",
        "The conditioning encoder is a dictionary with key `label` (and here the value is\n",
        "a `nn.Module` which is given by a simple `LabelEmbedding` module). If you want\n",
        "to train a purely unconditional model, set `conditioning_embedders = {}`."
      ],
      "metadata": {
        "id": "fqGG4Co-HD1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# Conditional diffusion.\n",
        "################################################################################\n",
        "\n",
        "ConditioningMechanism = arch_typing.ConditioningMechanism\n",
        "\n",
        "conditioning_embedders = {\n",
        "    'label': conditioning_encoder.LabelEmbedder(\n",
        "        num_classes=10,\n",
        "        num_features=256,\n",
        "        conditioning_key='label',\n",
        "    )\n",
        "}\n",
        "\n",
        "time_embedder_continuous = conditioning_encoder.SinusoidalTimeEmbedder(\n",
        "    activation='gelu', embedding_dim=256, num_features=256\n",
        ")\n",
        "time_embedder_discrete = conditioning_encoder.SinusoidalTimeEmbedder(\n",
        "    activation='gelu', embedding_dim=256, num_features=256\n",
        ")\n",
        "time_embedder = conditioning_encoder.NestedTimeEmbedder(\n",
        "    time_embedders={\n",
        "        'data_continuous': time_embedder_continuous,\n",
        "        'data_discrete': time_embedder_discrete,\n",
        "    }\n",
        ")\n",
        "\n",
        "encoder = conditioning_encoder.ConditioningEncoder(\n",
        "    time_embedder=time_embedder,\n",
        "    conditioning_embedders=conditioning_embedders,\n",
        "    embedding_merging_method=arch_typing.EmbeddingMergeMethod.SUM,\n",
        "    conditioning_rules={\n",
        "        'time': ConditioningMechanism.ADAPTIVE_NORM,\n",
        "        'label': ConditioningMechanism.ADAPTIVE_NORM,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "pDQv0FEEHFj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting all together into diffusion network"
      ],
      "metadata": {
        "id": "E9Cy-hgrH7gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = diffusion_network.MultiModalDiffusionNetwork(\n",
        "    backbone_network=backbone,\n",
        "    conditioning_encoder=encoder,\n",
        "    prediction_type={'data_continuous': 'x0', 'data_discrete': 'logits'},\n",
        "    data_dtype={'data_continuous': jnp.float32, 'data_discrete': jnp.int32},\n",
        "    input_rescaler=None,\n",
        "    time_rescaler=None,\n",
        ")"
      ],
      "metadata": {
        "id": "7EUVYISMH9bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model visualization"
      ],
      "metadata": {
        "id": "5rwfPG_EtTS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_depth = 2  # @param {type: \"integer\"}\n",
        "\n",
        "tabulate_fn = nn.tabulate(\n",
        "    network,\n",
        "    jax.random.PRNGKey(42),\n",
        "    depth=summary_depth,\n",
        "    console_kwargs={'force_jupyter': True, 'soft_wrap': True},\n",
        ")\n",
        "\n",
        "dummy_time = {\n",
        "    'data_continuous': jnp.ones((1, 1, 1, 1)),\n",
        "    'data_discrete': jnp.ones((1, 1, 1, 1, 1)),\n",
        "}\n",
        "dummy_xt = {\n",
        "    'data_continuous': jnp.ones((1, 28, 28, 3)),\n",
        "    'data_discrete': jnp.ones((1, 28, 28, 1, 1), dtype=jnp.int32),\n",
        "}\n",
        "dummy_conditioning = {'label': jnp.ones((1,)).astype(jnp.int32)}\n",
        "\n",
        "print(\n",
        "    tabulate_fn(\n",
        "        dummy_xt,\n",
        "        dummy_time,\n",
        "        dummy_conditioning,\n",
        "        is_training=False,\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "LvX6WLQGN1cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define time sampler, optimizer and loss function\n",
        "\n",
        "The time is sampled uniformly in the interval $[\\epsilon,1 - \\epsilon]$.\n",
        "\n",
        "The loss is simply the $\\ell_2$ loss."
      ],
      "metadata": {
        "id": "emGbkd8vMWyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_sampler = time_sampling.JointNestedTimeSampler(\n",
        "    samplers={\n",
        "        \"data_continuous\": time_sampling.UniformTimeSampler(\n",
        "            safety_epsilon=1e-3\n",
        "        ),\n",
        "        \"data_discrete\": time_sampling.UniformTimeSampler(safety_epsilon=1e-3),\n",
        "    }\n",
        ")\n",
        "\n",
        "optimizer = optax.chain(\n",
        "    optax.clip_by_global_norm(max_norm=1.0),\n",
        "    optax.scale_by_adam(b1=0.9, b2=0.999, eps=1e-8),\n",
        "    optax.scale_by_schedule(optax.constant_schedule(value=5e-4)),\n",
        "    optax.scale(-1.0),\n",
        ")\n",
        "\n",
        "loss_fn_continuous = gaussian_loss.NoWeightLoss()\n",
        "loss_fn_discrete = discrete_loss.DiffusionCrossEntropyLoss(\n",
        "    schedule=schedule_discrete\n",
        ")\n",
        "loss_fn = base_loss.NestedDiffusionLoss(\n",
        "    losses={\n",
        "        \"data_continuous\": loss_fn_continuous,\n",
        "        \"data_discrete\": loss_fn_discrete,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "1Y-S0iHuIa9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the parameters loss function and gradient function\n",
        "\n",
        "Here we define the loss function as well as gradient function to be dependent on\n",
        "NN parameters. This is needed for training the neural network."
      ],
      "metadata": {
        "id": "qYyGqTogMdp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def params_loss_fn(params, x0, conditioning, rng):\n",
        "  time_rng, corrupt_rng = jax.random.split(rng, 2)\n",
        "  time = time_sampler(key=time_rng, data_spec=x0)\n",
        "  xt, targets = process.corrupt(key=corrupt_rng, x0=x0, time=time)\n",
        "  output = network.apply(\n",
        "      {'params': params},\n",
        "      time=time,\n",
        "      xt=xt,\n",
        "      conditioning=conditioning,\n",
        "      is_training=True,\n",
        "      rngs={'dropout': rng},\n",
        "  )\n",
        "  losses = loss_fn(preds=output, targets=targets, time=time)\n",
        "  leaves, _ = jax.tree_util.tree_flatten(losses)\n",
        "  out = jnp.mean(jnp.stack(leaves))\n",
        "  return out, {'loss': out}\n",
        "\n",
        "\n",
        "grad_fn = jax.jit(jax.grad(params_loss_fn, has_aux=True))"
      ],
      "metadata": {
        "id": "Pun40gVLtsf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrapping the whole update into `update_fn` since it makes the updates much\n",
        "faster"
      ],
      "metadata": {
        "id": "QZeLtgeGR8uI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def update_fn(params, opt_state, x0, conditioning, rng):\n",
        "  grads, metrics = grad_fn(params, x0, conditioning, rng)\n",
        "  updates, opt_state = optimizer.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state, metrics"
      ],
      "metadata": {
        "id": "_uXRZ2hSRjEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "Training the model should take less than 10 minutes."
      ],
      "metadata": {
        "id": "e3ebC1hxIcVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nepochs = 20\n",
        "batch_size = 256\n",
        "epoch_size = 60000 // batch_size"
      ],
      "metadata": {
        "id": "oRqMSxTmIeYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "\n",
        "import tqdm\n",
        "\n",
        "params = network.initialize_variables(\n",
        "    input_shape={\n",
        "        'data_continuous': (1, 28, 28, 3),\n",
        "        'data_discrete': (1, 28, 28, 1, 1),\n",
        "    },\n",
        "    conditioning_shape={'label': (1,)},\n",
        "    key=rng,\n",
        "    is_training=True,\n",
        ")['params']\n",
        "\n",
        "opt_state = optimizer.init(params)\n",
        "\n",
        "train_iter = iter(mnist_dataset(batch_size, train=True))\n",
        "\n",
        "losses = []\n",
        "for epoch in tqdm.tqdm(range(1, nepochs + 1)):\n",
        "  epoch_loss = steps = 0\n",
        "  for i in range(epoch_size):\n",
        "    # Read batch of data\n",
        "    batch = next(train_iter)\n",
        "    x0 = batch['data']\n",
        "    conditioning = {'label': batch['label']}\n",
        "    # Make the parameters update\n",
        "    rng, _ = jax.random.split(rng)\n",
        "    params, opt_state, metrics = update_fn(\n",
        "        params, opt_state, x0, conditioning, rng\n",
        "    )\n",
        "    epoch_loss += metrics['loss']\n",
        "    steps += 1\n",
        "  print(f'Epoch = {epoch}, Cumulative epoch loss = {epoch_loss}')\n",
        "  losses.append(epoch_loss)"
      ],
      "metadata": {
        "id": "boqKlkENt4aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "metadata": {
        "id": "Zt9AlILeuyQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9dX8jwMpfuv"
      },
      "source": [
        "## It's inference time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qij2alwWphef"
      },
      "source": [
        "Below, we define the inference function. It creates a pure jax function which\n",
        "takes `t`, `xt` and `c` to return the expected value of `x0`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_inference_fn = wrappers.FlaxLinenInferenceFn(\n",
        "    network=network,\n",
        "    params=params,\n",
        ")\n",
        "inference_fn = diffusion_inference.GuidedDiffusionInferenceFn(\n",
        "    base_inference_fn=base_inference_fn\n",
        ")"
      ],
      "metadata": {
        "id": "A8nH-A6pPkVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampler -- time_schedule, stepper and sampler itself"
      ],
      "metadata": {
        "id": "BcVHlXAhPuY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stochasticity_level = 1.0  # Stochasticity coefficient in DDIM\n",
        "\n",
        "time_schedule_continuous = time_scheduling.UniformTimeSchedule()\n",
        "time_schedule_discrete = time_scheduling.UniformTimeSchedule()\n",
        "time_schedule = time_scheduling.NestedTimeSchedule(\n",
        "    time_schedules={\n",
        "        'data_continuous': time_schedule_continuous,\n",
        "        'data_discrete': time_schedule_discrete,\n",
        "    }\n",
        ")\n",
        "\n",
        "stepper_continuous = gaussian_step_sampler.DDIMStep(\n",
        "    corruption_process=process_continuous, stoch_coeff=stochasticity_level\n",
        ")\n",
        "\n",
        "num_sampling_steps = 100  # Number of denoising steps\n",
        "stepper_discrete = discrete_step_sampler.UnMaskingStep(\n",
        "    corruption_process=process_discrete\n",
        ")\n",
        "\n",
        "stepper = base_sampler.NestedSamplerStep(\n",
        "    sampler_steps={\n",
        "        'data_continuous': stepper_continuous,\n",
        "        'data_discrete': stepper_discrete,\n",
        "    }\n",
        ")\n",
        "\n",
        "sampler = sampling.DiffusionSampler(\n",
        "    time_schedule=time_schedule, stepper=stepper, num_steps=num_sampling_steps\n",
        ")\n",
        "sampler = functools.partial(sampler, inference_fn=inference_fn)\n",
        "sampler = jax.jit(jax.experimental.checkify.checkify(sampler))"
      ],
      "metadata": {
        "id": "sLpq6yoWw7rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling the data\n",
        "\n",
        "*   First, we sample the data taking the conditioning from a batch of data,\n",
        "    allowing to approximate $p(x_0)$\n",
        "\n",
        "*   Second, we sample data with a given label, allowing to sample $p(x_0 | c)$"
      ],
      "metadata": {
        "id": "yTHo_XNGP0lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = jax.tree.map(lambda x: jnp.array(x), x0)\n",
        "\n",
        "initial_noise = process.sample_from_invariant(key=rng, data_spec=x0)"
      ],
      "metadata": {
        "id": "qq11x98YmFOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_w_9y8OW8nz"
      },
      "outputs": [],
      "source": [
        "num_samples = 256\n",
        "specific_label = 5\n",
        "\n",
        "eval_iter = iter(mnist_dataset(num_samples, train=False))\n",
        "eval_data = next(eval_iter)\n",
        "\n",
        "################################################################################\n",
        "# Sample conditionally using dataset\n",
        "################################################################################\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "\n",
        "conditioning = {\"label\": eval_data[\"label\"]}\n",
        "_, (out_cond, _) = sampler(\n",
        "    rng=key, initial_noise=initial_noise, conditioning=conditioning\n",
        ")\n",
        "\n",
        "################################################################################\n",
        "# Sample from a given label\n",
        "################################################################################\n",
        "\n",
        "key = jax.random.PRNGKey(1)\n",
        "conditioning = {\n",
        "    \"label\": jnp.ones((num_samples,)).astype(jnp.int32) * specific_label\n",
        "}\n",
        "_, (out_label, _) = sampler(\n",
        "    rng=key, initial_noise=initial_noise, conditioning=conditioning\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize samples from $p(x_0)$"
      ],
      "metadata": {
        "id": "DmsEJpC2VQ1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_mnist_plot_images = out_cond['data_continuous'].xt\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(cur_mnist_plot_images[:64], axes.flatten()):\n",
        "  ax.imshow(img)\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q7dxWHBPVPTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur_mnist_plot_images = out_cond['data_discrete'].xt\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(cur_mnist_plot_images[:64][..., 0], axes.flatten()):\n",
        "  ax.imshow(img)\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R76IObMi2hcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize samples from $p(x_0 | c)$"
      ],
      "metadata": {
        "id": "PEsoaSmsVVuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cur_mnist_plot_images = out_label['data_continuous'].xt\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(cur_mnist_plot_images[:64], axes.flatten()):\n",
        "  ax.imshow(img)\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A4ljuY8cVVuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur_mnist_plot_images = out_label['data_discrete'].xt\n",
        "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
        "for img, ax in zip(cur_mnist_plot_images[:64][..., 0], axes.flatten()):\n",
        "  ax.imshow(img)\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iB4ltswh5tDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hO86nMs_X3A2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/dm_python:dm_notebook3_tpu",
        "kind": "private"
      }
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
